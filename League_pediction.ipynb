{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://fbref.com/en/comps/8/2023-2024/schedule/2023-2024-Champions-League-Scores-and-Fixtures",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 104\u001b[0m\n\u001b[0;32m    101\u001b[0m ucl_2024_25 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://fbref.com/en/comps/8/2024-2025/schedule/2024-2025-Champions-League-Scores-and-Fixtures\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# SCRAPE BOTH SEASONS\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m df_2023_24 \u001b[38;5;241m=\u001b[39m scrape_ucl(ucl_2023_24)\n\u001b[0;32m    105\u001b[0m df_2024_25 \u001b[38;5;241m=\u001b[39m scrape_ucl(ucl_2024_25)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2023–24 Matches:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_2023_24))\n",
      "Cell \u001b[1;32mIn[8], line 58\u001b[0m, in \u001b[0;36mscrape_ucl\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscrape_ucl\u001b[39m(url):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# download page\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mHEADERS)\n\u001b[1;32m---> 58\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     60\u001b[0m     soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(response\u001b[38;5;241m.\u001b[39mtext, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Find the first table on the page (FBref schedules always use this)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1018\u001b[0m     )\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://fbref.com/en/comps/8/2023-2024/schedule/2023-2024-Champions-League-Scores-and-Fixtures"
     ]
    }
   ],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "\n",
    "# def scrape_ucl_season(url):\n",
    "#     html=requests.get(url).text\n",
    "#     soup=BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "#     matches=[]\n",
    "\n",
    "#     table=soup.find(\"table\",{\"id\":\"sched_8_2023-2024_8\"}) or \\\n",
    "#           soup.find(\"table\",{\"id\":\"sched_8_2023-2024_8\"}) or \\\n",
    "#           soup.find('table')\n",
    "\n",
    "#     for row in table.find_all('tr'):\n",
    "#         cols=row.find_all('td')\n",
    "\n",
    "\n",
    "#         if len(cols)<5:\n",
    "#             continue\n",
    "\n",
    "\n",
    "#         date=cols[0].text.strip()\n",
    "#         home=cols[2].text.strip()\n",
    "#         score=cols[3].text.strip()\n",
    "#         away=cols[4].text.strip()\n",
    "        \n",
    "\n",
    "#         if score ==\"\":\n",
    "#             continue\n",
    "\n",
    "#         matches.append({\n",
    "#             \"date\":date,\n",
    "#             \"home_team\":home,\n",
    "#             \"away_team\":away,\n",
    "#             \"score\":score\n",
    "#         })\n",
    "\n",
    "#         return pd.Dataframe(matches)\n",
    "    \n",
    "# ucl_2023= \"https://fbref.com/en/comps/8/2023-2024/schedule/2023-2024-Champions-League-Scores-and-Fixtures\"\n",
    "# # ucl_2024 = \"https://fbref.com/en/comps/8/2024-2025/schedule/2024-2025-Champions-League-Scores-and-Fixtures\"  \n",
    "# ucl_2024=\"https://fbref.com/en/comps/8/2023-2024/schedule/2023-2024-Champions-League-Scores-and-Fixtures\",\n",
    "# df_2023=scrape_ucl_season(ucl_2024)\n",
    "\n",
    "# df_2023.head()\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "HEADERS = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "def scrape_ucl(url):\n",
    "    # download page\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find the first table on the page (FBref schedules always use this)\n",
    "    table = soup.find(\"table\")\n",
    "    if table is None:\n",
    "        raise Exception(\"No table found on the page.\")\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    for row in table.find_all(\"tr\"):\n",
    "        cols = row.find_all(\"td\")\n",
    "        if len(cols) < 5:\n",
    "            continue\n",
    "\n",
    "        date = cols[0].get_text(strip=True)\n",
    "        home = cols[2].get_text(strip=True)\n",
    "        score = cols[3].get_text(strip=True)\n",
    "        away = cols[4].get_text(strip=True)\n",
    "\n",
    "        # Skip future fixtures (score missing)\n",
    "        if not re.search(r\"\\d+\\s*[–-]\\s*\\d+\", score):\n",
    "            continue\n",
    "\n",
    "        # Extract goals\n",
    "        m = re.search(r\"(\\d+)\\s*[–-]\\s*(\\d+)\", score)\n",
    "        home_goals = int(m.group(1))\n",
    "        away_goals = int(m.group(2))\n",
    "\n",
    "        matches.append({\n",
    "            \"date\": date,\n",
    "            \"home_team\": home,\n",
    "            \"away_team\": away,\n",
    "            \"home_goals\": home_goals,\n",
    "            \"away_goals\": away_goals\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(matches)\n",
    "\n",
    "\n",
    "# REAL WORKING FBREF URLS (NO TUPLES!)\n",
    "ucl_2023_24 = \"https://fbref.com/en/comps/8/2023-2024/schedule/2023-2024-Champions-League-Scores-and-Fixtures\"\n",
    "ucl_2024_25 = \"https://fbref.com/en/comps/8/2024-2025/schedule/2024-2025-Champions-League-Scores-and-Fixtures\"\n",
    "\n",
    "# SCRAPE BOTH SEASONS\n",
    "df_2023_24 = scrape_ucl(ucl_2023_24)\n",
    "df_2024_25 = scrape_ucl(ucl_2024_25)\n",
    "\n",
    "print(\"\\n2023–24 Matches:\", len(df_2023_24))\n",
    "print(df_2023_24.head())\n",
    "\n",
    "print(\"\\n2024–25 Matches:\", len(df_2024_25))\n",
    "print(df_2024_25.head())\n",
    "\n",
    "# Save CSVs\n",
    "df_2023_24.to_csv(\"ucl_2023_24.csv\", index=False)\n",
    "df_2024_25.to_csv(\"ucl_2024_25.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
